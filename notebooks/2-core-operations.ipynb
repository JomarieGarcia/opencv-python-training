{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread('bernie.jpg', cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "image = cv2.imread('bernie.jpg', cv2.IMREAD_COLOR)\n",
    "#Cropping Image\n",
    "#\n",
    "\n",
    "image = cv2.imread('bernie.jpg', cv2.IMREAD_COLOR)\n",
    "croppedImage = image[302:(302+322), 261:(261+339)]\n",
    "def show_image(croppedImage):\n",
    "    cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('image', croppedImage)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "show_image(croppedImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape)\n",
    "print(image.size)\n",
    "print(image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Modifying Image\n",
    "#\n",
    "\n",
    "modifiedImage = image[302:(302+322), 261:(261+339)]\n",
    "modifiedImage[:,:,0] = 123\n",
    "show_image_modified(modifiedImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Making a white portion in an image (or what color it is)\n",
    "#\n",
    "\n",
    "image[302:(302+322), 261:(261+339)] = 100\n",
    "show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Cropping Image (with selection)\n",
    "#\n",
    "\n",
    "from_center = False\n",
    "region = cv2.selectROI(image, from_center)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 76, 468, 188)\n"
     ]
    }
   ],
   "source": [
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageROI = image[region[1]:(region[1]+region[3]), region[0]:(region[0] + region[2])]\n",
    "show_image(imageROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Image Grayed Out\n",
    "#\n",
    "\n",
    "grayscale_bernie = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "show_image(grayscale_bernie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('bernie.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "invertedimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "show_image(invertedimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSVimage = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "show_image(HSVimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# combining image\n",
    "#\n",
    "\n",
    "bernie = cv2.imread('bernie.jpg', cv2.IMREAD_COLOR)\n",
    "howie = cv2.imread('howie.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "sum_image = cv2.add(bernie, howie)\n",
    "show_image(sum_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# blending image\n",
    "#\n",
    "\n",
    "blended = cv2.addWeighted(bernie, 0.5, howie, 0.5, 0)\n",
    "show_image(blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing the image\n",
    "big_bang = cv2.imread('big-bang.jpg', cv2.IMREAD_COLOR)\n",
    "big_bang = cv2.resize(big_bang, (int(big_bang.shape[1] * 0.25), int(big_bang.shape[0] * 0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 159, 3)\n"
     ]
    }
   ],
   "source": [
    "print(big_bang.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proprties of the logo\n",
    "rows, cols, channels = big_bang.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = bernie[0:rows, 0:cols]\n",
    "show_image(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask of the logo\n",
    "\n",
    "#convert the image to grayscale for thresholding\n",
    "bigbang_gray = cv2.cvtColor(big_bang, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#first argument is the source image\n",
    "#second argument is the threshold value\n",
    "#third argument is the value to use if threshold is reached\n",
    "#cv2.THRESH_BINARY_INV reverses the condition of the third argument\n",
    "\n",
    "ret, mask = cv2.threshold(bigbang_gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "show_image(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the inverse mask\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "show_image(mask_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#black out the are of logo in ROI\n",
    "\n",
    "bernie_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "show_image(bernie_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the region of logo from logo image\n",
    "bigbang_fg = cv2.bitwise_and(big_bang, big_bang, mask=mask)\n",
    "show_image(bigbang_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the logo on region of interest\n",
    "dst = cv2.add(bernie_bg, bigbang_fg)\n",
    "bernie[0:rows, 0:cols] = dst\n",
    "\n",
    "show_image(bernie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exercise 1\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "jomarie = cv2.imread('../assets/myImage.jpg', cv2.IMREAD_COLOR)\n",
    "accenture = cv2.imread('../assets/accenture.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "cv2.imwrite('myImage.jpg', jomarie)\n",
    "cv2.imwrite('accenture.png', accenture)\n",
    "\n",
    "accenture = cv2.imread('accenture.png', cv2.IMREAD_COLOR)\n",
    "accenture = cv2.resize(accenture, (int(accenture.shape[1] * 0.25), int(accenture.shape[0] * 0.25)))\n",
    "\n",
    "rows, cols, channels = accenture.shape\n",
    "\n",
    "roi = jomarie[0:rows, 0:cols]\n",
    "\n",
    "accenture_gray = cv2.cvtColor(accenture, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, mask = cv2.threshold(accenture_gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "jomarie_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "accenture_fg = cv2.bitwise_and(accenture, accenture, mask=mask)\n",
    "\n",
    "dst = cv2.add(jomarie_bg, accenture_fg)\n",
    "jomarie[0:rows, 0:cols] = dst\n",
    "\n",
    "show_image(jomarie)\n",
    "\n",
    "\n",
    "cv2.imwrite('jomarie.jpg', jomarie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-8c0604c780a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccenture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mroi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0maccenture_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccenture\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#exercise 2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    accenture = cv2.imread('../assets/accenture.png', cv2.IMREAD_COLOR)\n",
    "    cv2.imwrite('accenture.png', accenture)\n",
    "\n",
    "    accenture = cv2.imread('accenture.png', cv2.IMREAD_COLOR)\n",
    "    accenture = cv2.resize(accenture, (int(accenture.shape[1] * 0.25), int(accenture.shape[0] * 0.25)))\n",
    "\n",
    "    rows, cols, channels = accenture.shape\n",
    "\n",
    "    roi = frame[0:rows, 0:cols]\n",
    "\n",
    "    accenture_gray = cv2.cvtColor(accenture, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, mask = cv2.threshold(accenture_gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    frame_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "\n",
    "    accenture_fg = cv2.bitwise_and(accenture, accenture, mask=mask)\n",
    "\n",
    "    dst = cv2.add(frame_bg, accenture_fg)       \n",
    "    frame[0:rows, 0:cols] = dst\n",
    "\n",
    "    cv2.imshow('webcam', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('bernie.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "blue, green, red = cv2.split(image)\n",
    "\n",
    "show_image(green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "slice step cannot be zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-9e82fbacdcc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bernie.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 0=blue, 1=green, 2=red\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mblue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: slice step cannot be zero"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
